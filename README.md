# XAI Mini-Projet : Attention is Not Explanation - Read the Docs

Documentation complÃ¨te basÃ©e sur le notebook Jupyter `Projet7_Attention_Not_Explanation.ipynb`.

## ğŸ“š Ã€ Propos

Ce projet est une Ã©tude empirique combinant recherche acadÃ©mique et implÃ©mentation pratique pour rÃ©pondre Ã  une question fondamentale en explicabilitÃ© de l'IA :

**Les poids d'attention des Transformers constituent-ils de vÃ©ritables explications des dÃ©cisions du modÃ¨le ?**

## ğŸ¯ Contenu

La documentation est organisÃ©e en 8 sections principales :

1. **Contexte & Motivation** - DÃ©bat scientifique entre Jain & Wallace (2019) et Wiegreffe & Pinter (2019)
2. **Intuition de la MÃ©thode** - Explication conceptuelle du mÃ©canisme d'attention
3. **Formalisation MathÃ©matique** - Ã‰quations et mÃ©triques rigoureuses
4. **ImplÃ©mentation Pratique** - Guide d'installation et code reproductible
5. **ExpÃ©riences & Visualisations** - RÃ©sultats empiriques et analyses
6. **Discussion Critique** - Forces, limitations et recommandations
7. **Conclusion & Points ClÃ©s** - SynthÃ¨se et implications pratiques
8. **RÃ©fÃ©rences** - Bibliographie complÃ¨te (12+ articles majeurs)

Plus : **Glossaire** et **FAQ**

## âš¡ RÃ©sumÃ© ExÃ©cutif

### RÃ©sultat Principal
CorrÃ©lation de Spearman moyenne entre **Attention** et **LIME** = **0.31**

Cela indique une **corrÃ©lation faible**, insuffisante pour garantir que l'attention seule constitue une explication fiable.

### Conclusions
- âœ“ L'attention offre des insights utiles pour l'exploration
- âœ— L'attention n'est pas une explication causale  
- âš  L'attention Ã©choue systÃ©matiquement sur les nÃ©gations
- âœ“ Valider avec LIME/SHAP avant utilisation en production

## ğŸš€ Comment AccÃ©der Ã  la Documentation

### Option 1 : Construire localement avec Sphinx

```bash
# 1. Installer les dÃ©pendances
cd docs
pip install -r requirements.txt

# 2. Construire HTML
make html

# 3. Ouvrir dans le navigateur
open build/html/index.html  # macOS/Linux
start build\html\index.html # Windows
```

### Option 2 : Lire les fichiers .rst directement

```bash
# Les fichiers source sont dans docs/source/
cat docs/source/1_contexte_motivation.rst
cat docs/source/2_intuition_methode.rst
# etc.
```

### Option 3 : DÃ©ployer sur ReadTheDocs.org

1. Forker le repo
2. CrÃ©er compte sur https://readthedocs.org
3. Importer le projet
4. ReadTheDocs construit automatiquement

## ğŸ“Š Structure des Fichiers

```
read-the-doc/
â”œâ”€â”€ Projet7_Attention_Not_Explanation.ipynb  â† Notebook source
â”œâ”€â”€ README.md                                 â† Ce fichier
â””â”€â”€ docs/
    â”œâ”€â”€ requirements.txt                      â† DÃ©pendances Sphinx
    â””â”€â”€ source/
        â”œâ”€â”€ conf.py                           â† Configuration Sphinx
        â”œâ”€â”€ index.rst                         â† Page d'accueil
        â”œâ”€â”€ 1_contexte_motivation.rst
        â”œâ”€â”€ 2_intuition_methode.rst
        â”œâ”€â”€ 3_formalisation_mathematique.rst
        â”œâ”€â”€ 4_implementation_pratique.rst
        â”œâ”€â”€ 5_experiences_visualisations.rst
        â”œâ”€â”€ 6_discussion_critique.rst
        â”œâ”€â”€ 7_conclusion_points_cles.rst
        â”œâ”€â”€ 8_references.rst
        â”œâ”€â”€ glossaire.rst
        â”œâ”€â”€ faq.rst
        â”œâ”€â”€ footer.rst
        â”œâ”€â”€ _static/                         â† Ressources statiques
        â””â”€â”€ _templates/                      â† Templates HTML
```

## ğŸ”§ PrÃ©-requis Techniques

### Pour Jupyter (Notebook)
```bash
pip install torch transformers lime shap matplotlib seaborn pandas numpy scipy
```

### Pour Sphinx (Documentation)
```bash
pip install sphinx sphinx-rtd-theme
```

## ğŸ“– Lectures RecommandÃ©es

### DÃ©butant (30 minutes)
1. Cette README
2. Section "Intuition de la MÃ©thode" (Index â†’ 2)
3. FAQ

### IntermÃ©diaire (2-3 heures)
1. Sections 1-5 complÃ¨tes
2. Glossaire pour clarifications
3. RÃ©fÃ©rences pour les articles clÃ©s

### AvancÃ© (1 jour+)
1. Toute la documentation
2. Relire le notebook Jupyter
3. Reproduire les expÃ©riences
4. Lire les 12 articles de rÃ©fÃ©rence

## ğŸ“ Apprenants Cibles

âœ“ **Ã‰tudiants** en IA/ML : Comprendre XAI  
âœ“ **Data Scientists** : ImplÃ©menter LIME/SHAP responsablement  
âœ“ **Chercheurs** : Investiguer explicabilitÃ© de l'IA  
âœ“ **Product Managers** : DÃ©cider quand utiliser l'attention  
âœ“ **Policy Makers** : RÃ©glementer l'IA explicable  

## ğŸ” Points ClÃ©s

### Forces de l'Attention
- âš¡ TrÃ¨s rapide (gratuit Ã  infÃ©rence)
- ğŸ¨ Facile Ã  visualiser et interprÃ©ter
- ğŸ”¬ GranularitÃ© dÃ©taillÃ©e (couches, tÃªtes, tokens)
- ğŸ§  RÃ©vÃ¨le les patterns internes du modÃ¨le

### Limitations de l'Attention
- âŒ Non causale (observation â‰  causalitÃ©)
- ğŸ­ AmbiguÃ¯tÃ© multi-tÃªtes
- ğŸ“ Bias positionnel
- ğŸš« Ã‰choue sur les nÃ©gations
- ğŸª Manipulable (permutation sans effet)

## ğŸ’¡ Recommandations Pratiques

### Pipeline XAI Responsable
```
1. Extraction    â†’ Attention + LIME + SHAP
2. Validation    â†’ CorrÃ©lation Spearman > 0.5 ?
3. Classement    â†’ Simple vs Complexe
4. Affichage     â†’ Attention (simple) ou LIME/SHAP (complexe)
5. Audit         â†’ Tests adversariaux
```

### Quand Utiliser Quoi
| Contexte | Attention | LIME | SHAP |
|----------|:---------:|:----:|:----:|
| DÃ©bugage rapide | âœ“ | - | - |
| Exploration | âœ“ | âœ“ | - |
| Validation | - | âœ“ | âœ“ |
| Production sensible | - | âœ“ | âœ“ |
| ConformitÃ© GDPR | âš  | âœ“ | âœ“ |

## ğŸ¤ Contribution

Les contributions sont bienvenues !

- **Corrections** : Typos, formulations, code
- **Extensions** : Nouveaux cas d'Ã©tude, langues, modÃ¨les
- **Discussions** : Issues et discussions GitHub

## ğŸ“„ Licence

Libre d'usage pour fins **Ã©ducatives et de recherche**.

Citation recommandÃ©e :
```bibtex
@misc{XAIAttentionProject2025,
  title={Mini-Projet XAI: Attention is Not Explanation},
  author={[Vos noms]},
  year={2025},
  institution={[Votre institution]},
  url={https://[votre-repo]}
}
```

## ğŸ”— Ressources Externes

### Articles ClÃ©s
- Jain & Wallace (2019) - "Attention is Not Explanation"
- Wiegreffe & Pinter (2019) - "Attention is Not Not Explanation"
- Vaswani et al. (2017) - "Attention is All You Need"

### Outils
- HuggingFace Transformers : https://huggingface.co/transformers/
- SHAP : https://shap.readthedocs.io/
- LIME : https://github.com/marcotcr/lime

### Cours
- Stanford CS224N : https://cs224n.stanford.edu/
- HuggingFace Course : https://huggingface.co/course

## ğŸ“ Support

- **Issues** : GitHub Issues (ce repo)
- **Discussions** : GitHub Discussions
- **Email** : [contact des auteurs]

## ğŸ‰ Remerciements

Merci Ã  :
- Jain & Wallace pour avoir soulevÃ© la question
- Wiegreffe & Pinter pour avoir nuancÃ© le dÃ©bat
- La communautÃ© NLP/XAI pour les discussions continues

---

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2025  
**Version** : 1.0  
**Statut** : Complet et reproductible
