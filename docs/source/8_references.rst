.. _references:

==========
8. R√©f√©rences
==========

.. contents::
   :local:
   :depth: 2

---

Articles Fondateurs du D√©bat
=============================

**[1] Jain, S., & Wallace, B. C. (2019).**

"Attention is Not Explanation"

*Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)*

ArXiv: https://arxiv.org/abs/1902.10186  
DOI: 10.18653/v1/N19-1357

**R√©sum√©** :

Les auteurs d√©montrent que :

- Les poids d'attention peuvent √™tre permut√©s sans changer la pr√©diction
- Des distributions alternatives d'attention produisent les m√™mes r√©sultats
- L'attention a une corr√©lation faible avec les gradients
- L'attention n'explique pas les d√©cisions du mod√®le de mani√®re fiable

**Impact** : Article tr√®s influent (~2000+ citations) qui a remis en question l'usage des heatmaps d'attention comme explications.

---

**[2] Wiegreffe, S., & Pinter, Y. (2019).**

"Attention is Not Not Explanation"

*Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)*

ArXiv: https://arxiv.org/abs/1908.04626  
DOI: 10.18653/v1/D19-1002

**R√©sum√©** :

Les auteurs r√©pondent aux critiques de Jain & Wallace :

- Les tests de Jain & Wallace sont m√©thodologiquement discutables
- L'attention peut √™tre une explication valide sous certaines conditions
- Distinction importante : explication vs explication fid√®le
- L'attention reste informative quand interpr√©t√©e correctement

**Impact** : Apporte une nuance importante au d√©bat, montrant que la r√©ponse n'est pas binaire.

---

Articles de Contexte
====================

**[3] Vaswani, A., et al. (2017).**

"Attention is All You Need"

*Advances in Neural Information Processing Systems (NeurIPS)*

ArXiv: https://arxiv.org/abs/1706.03762  
DOI: 10.5555/3294996.3295043

**R√©sum√©** :

L'article fondateur des Transformers et du m√©canisme d'attention moderne.

Introduit :

- Scaled Dot-Product Attention
- Multi-Head Attention
- Architecture enti√®rement bas√©e sur l'attention

**Impact** : R√©volutionnaire, a lanc√© l'√®re des mod√®les Transformer (BERT, GPT, etc.)

---

**[4] Devlin, J., et al. (2019).**

"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"

*Proceedings of NAACL-HLT 2019*

ArXiv: https://arxiv.org/abs/1810.04805

**R√©sum√©** :

Introduit BERT (Bidirectional Encoder Representations from Transformers).

BERT est un Transformer pr√©-entra√Æn√© sur de grands corpus de texte.

Peut √™tre fine-tun√© pour diverses t√¢ches NLP.

**Impact** : BERT a r√©volutionn√© le NLP et est la base de nombreux mod√®les (DistilBERT, RoBERTa, etc.)

---

**[5] Sanh, V., et al. (2020).**

"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"

*Findings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*

ArXiv: https://arxiv.org/abs/1910.01108

**R√©sum√©** :

DistilBERT est une version compress√©e de BERT avec 40% moins de param√®tres.

Conserve 97% des performances avec vitesse 60% plus rapide.

C'est le mod√®le utilis√© dans notre √©tude.

**Impact** : Permet le d√©ploiement pratique de Transformers fine-tuning.

---

Explicabilit√© et Interpr√©tabilit√©
==================================

**[6] Ribeiro, M. T., Singh, S., & Guestrin, C. (2016).**

"Why Should I Trust You?: Explaining the Predictions of Any Classifier"

*Proceedings of the 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)*

ArXiv: https://arxiv.org/abs/1602.04938

**R√©sum√©** :

Introduit **LIME** (Local Interpretable Model-agnostic Explanations).

LIME perturbe l'entr√©e localement et entra√Æne un mod√®le lin√©aire pour estimer l'importance des features.

**Impact** : M√©thode tr√®s influente pour l'XAI local, model-agnostic.

---

**[7] Lundberg, S. M., & Lee, S.-I. (2017).**

"A Unified Approach to Interpreting Model Predictions"

*Advances in Neural Information Processing Systems (NeurIPS)*

ArXiv: https://arxiv.org/abs/1705.07874

**R√©sum√©** :

Introduit **SHAP** (SHapley Additive exPlanations).

SHAP calcule les valeurs de Shapley de la th√©orie des jeux coop√©ratifs pour expliquer les pr√©dictions.

**Propri√©t√©s** :

- Th√©oriquement fond√©e (satisfait efficacit√©, sym√©trie, etc.)
- Model-agnostic
- Co√ªteuse en calcul mais tr√®s robuste

**Impact** : Devient le gold standard pour l'explicabilit√© en ML.

---

**[8] Montavon, G., Samek, W., & M√ºller, K. (2017).**

"Methods for Interpreting and Understanding Deep Neural Networks"

*Digital Signal Processing*

ArXiv: https://arxiv.org/abs/1706.07979

**R√©sum√©** :

Survey complet des m√©thodes d'interpr√©tabilit√© pour les r√©seaux profonds.

Couvre :

- Feature importance
- Perturbation-based methods
- Gradient-based methods
- Layer-wise relevance propagation

**Impact** : Reference compl√®te pour les chercheurs en XAI.

---

Critiques Compl√©mentaires de l'Attention
=========================================

**[9] Serrano, S., & Smith, N. A. (2019).**

"Is Attention Interpretable?"

*Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)*

ArXiv: https://arxiv.org/abs/1906.03731

**R√©sum√©** :

Analyse critiquement si l'attention peut √™tre interpr√©t√©e comme une mesure d'importance.

Montre :

- Attention confond importance et similarit√©
- Biais vers les self-attention
- Instabilit√© √† travers diff√©rents fine-tunings

**Impact** : Renforce les critiques de Jain & Wallace avec des analyses additionnelles.

---

**[10] Clark, K., Khandelwal, U., Levy, O., & Manning, C. D. (2019).**

"What Does BERT Look At? An Analysis of BERT's Attention"

*BlackboxNLP Workshop at ACL 2019*

ArXiv: https://arxiv.org/abs/1906.04341

**R√©sum√©** :

Analyse empiriquement ce que les diff√©rentes couches et t√™tes de BERT font :

- Couches basses : syntaxe locale
- Couches interm√©diaires : relations de phrase
- Couches hautes : patterns s√©mantiques

Mais montre aussi que beaucoup de t√™tes sont sans interpr√©tation claire.

**Impact** : Fournit des insights sur la structure de BERT, mais aussi sur la variabilit√© de l'attention.

---

Causality et Explicabilit√©
===========================

**[11] Pearl, J. (2009).**

"Causality: Models, Reasoning, and Inference" (2nd Edition)

*Cambridge University Press*

ISBN: 978-0521895589

**R√©sum√©** :

Trait√© fondamental sur la causalit√© en statistiques et en graphes causaux.

Introduit :

- Directed Acyclic Graphs (DAGs)
- D-separation et backdoor criterion
- Interventions et counterfactuals

**Impact** : Fondamental pour comprendre pourquoi l'attention n'est pas causale.

---

**[12] Goyal, Y., et al. (2019).**

"Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR"

*Harvard Journal of Law & Technology*

ArXiv: https://arxiv.org/abs/1711.00399

**R√©sum√©** :

Discute des explications contrefactuelles pour la conformit√© GDPR.

Argument : Pour vraiment expliquer une d√©cision, il faut montrer comment la modifier.

**Impact** : Important pour les applications r√©glementaires de l'XAI.

---

Ressources d'Apprentissage
===========================

**Pour D√©buter** üü¢

1. **Blog : The Illustrated Transformer** (Jay Alammar)
   
   https://jalammar.github.io/illustrated-transformer/
   
   Excellente introduction visuelle aux Transformers.

2. **Blog : The Illustrated BERT, ELMo, and co.** (Jay Alammar)
   
   https://jalammar.github.io/illustrated-bert/
   
   Explication visuelle de BERT.

3. **Hugging Face Course** 
   
   https://huggingface.co/course
   
   Cours complet et gratuit sur les Transformers.

---

**Pour Approfondir** üü°

1. **Explainability in Deep Learning**
   
   https://github.com/slundberg/shap
   
   Repository SHAP avec examples.

2. **Interpretable Machine Learning**
   
   https://christophm.github.io/interpretable-ml-book/
   
   Livre complet sur l'interpr√©tabilit√© en ML (version web libre).

3. **NLP with Transformers** (Tunstall et al., 2023)
   
   Book: O'Reilly Media
   
   Couvre les Transformers modernes et l'XAI.

---

**Pour Chercheurs** üî¥

1. **ACL Anthology**
   
   https://aclanthology.org/
   
   Repository de tous les articles NAACL/ACL/EMNLP.

2. **ArXiv NLP**
   
   https://arxiv.org/list/cs.CL/recent
   
   Preprints les plus r√©cents en NLP.

3. **SemEval Tasks**
   
   https://semeval.github.io/
   
   Shared tasks et benchmarks en NLP.

---

Donn√©es et Mod√®les
===================

**Datasets** üìä

- **SST-2** (Stanford Sentiment Treebank)
  
  https://huggingface.co/datasets/sst2
  
  Dataset d'analyse de sentiments utilis√© dans notre √©tude.

- **GLUE**
  
  https://gluebenchmark.com/
  
  Suite de 9 benchmarks NLP vari√©s.

---

**Mod√®les Pr√©-entra√Æn√©s** ü§ñ

- **DistilBERT**
  
  https://huggingface.co/distilbert-base-uncased
  
  Mod√®le utilis√© dans cette √©tude.

- **BERT**
  
  https://huggingface.co/bert-base-uncased
  
  Mod√®le original.

- **RoBERTa**
  
  https://huggingface.co/roberta-base
  
  Version optimis√©e de BERT.

- **ELECTRA**
  
  https://huggingface.co/google/electra-base-discriminator
  
  Alternative efficace avec pr√©-entra√Ænement adversarial.

---

Libraries et Outils
===================

**XAI Libraries** üîç

- **LIME** : https://github.com/marcotcr/lime
- **SHAP** : https://github.com/slundberg/shap
- **Captum** : https://github.com/pytorch/captum (PyTorch)
- **Alibi** : https://github.com/SeldonIO/alibi

**NLP & Deep Learning** üß†

- **Transformers (HuggingFace)** : https://huggingface.co/transformers/
- **PyTorch** : https://pytorch.org/
- **TensorFlow** : https://www.tensorflow.org/

**Visualization** üìä

- **Matplotlib** : https://matplotlib.org/
- **Seaborn** : https://seaborn.pydata.org/
- **Plotly** : https://plotly.com/python/
- **Altair** : https://altair-viz.github.io/

---

Conf√©rences et Workshops Pertinents
===================================

**Conf√©rences Majeures** üé§

- **ACL** : Association for Computational Linguistics (Annual)
- **EMNLP** : Conference on Empirical Methods in NLP (Annual)
- **NAACL** : North American Chapter ACL (Biennial)
- **NeurIPS** : Neural Information Processing Systems (Annual)

**Workshops Sp√©cialis√©s** üìç

- **BlackboxNLP** : Interpreting and Understanding Black-box NLP Models
  
  https://blackboxnlp.github.io/

- **XAI/LIME Workshop**
  
  Regularly at KDD, AAAI, etc.

---

Glossaire Technique Complet
============================

Voir la section **Glossaire** pour un glossaire d√©taill√© de tous les termes.

---

Questions Fr√©quemment Pos√©es
=============================

Voir la section **FAQ** pour les questions courantes.

---

Curation Finale
===============

**Lecture d'une semaine** (si vous avez le temps) :

.. code-block:: text

    Jour 1: Illustrated Transformer (blog)
    Jour 2: BERT paper + Jain & Wallace paper
    Jour 3: LIME et SHAP papers
    Jour 4: Ce notebook + exp√©riences
    Jour 5: Wiegreffe & Pinter + Serrano & Smith
    Jour 6: R√©sum√© personnalis√© + discussion
    Jour 7: Impl√©mentation personnelle

---

Citation Recommand√©e
====================

Si vous utilisez ce projet dans votre recherche :

.. code-block:: bibtex

    @misc{XAIAttentionProject2025,
      title={Mini-Projet XAI: Attention is Not Explanation},
      author={[Vos noms]},
      year={2025},
      institution={[Votre institution]},
      url={https://[votre-repo]}
    }

---
