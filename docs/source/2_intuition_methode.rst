.. _intuition-methode:

=========================
2. Intuition de la MÃ©thode
=========================

.. contents::
   :local:
   :depth: 2

---

L'IdÃ©e en Termes Simples
========================

Imaginez un **lecteur humain** qui doit dÃ©terminer si un avis de film est positif ou nÃ©gatif.

En lisant la phrase, ce lecteur va naturellement **focaliser son attention** sur certains mots :

.. code-block:: text

    "Le film est absolument [fantastique] et [merveilleux] !"
                              ^^^^^^^^^^^     ^^^^^^^^^^^
                         â†’ Mots clÃ©s observÃ©s

Ces mots clÃ©s (adjectifs, nÃ©gations, intensifieurs) influencent directement sa conclusion.

**La question** : Les modÃ¨les Transformer reproduisent-ils ce comportement de maniÃ¨re fiable ?

---

Le MÃ©canisme d'Attention ExpliquÃ©
==================================

Structure GÃ©nÃ©rale
~~~~~~~~~~~~~~~~~~~

Le Self-Attention fonctionne en trois Ã©tapes :

.. code-block:: text

    INPUT
      â†“
    [1] Calcul des Scores (Query Ã— Key)
      â†“
    [2] Normalisation par Softmax (probabilitÃ©s)
      â†“
    [3] PondÃ©ration des Valeurs
      â†“
    OUTPUT

Exemple Concret
~~~~~~~~~~~~~~~

ConsidÃ©rons la phrase :

.. code-block:: text

    "The film is good"

TokenizÃ©e comme :

.. code-block:: text

    [CLS] the film is good [SEP]
      0    1   2   3   4    5

**Ã‰tape 1 : Calcul des scores**

Pour le token "good" (position 4), le modÃ¨le calcule des "scores d'attention" vers tous les autres tokens :

.. math::
   
   \text{score}_{4 \to j} = query_4 \cdot key_j \quad \forall j

**Ã‰tape 2 : Normalisation**

Ces scores sont passÃ©s dans une fonction softmax pour obtenir des probabilitÃ©s :

.. math::
   
   \alpha_{4,j} = \frac{e^{\text{score}_{4 \to j}}}{\sum_k e^{\text{score}_{4 \to k}}}

RÃ©sultat :

.. code-block:: text

    Position: [CLS]  the   film   is   good  [SEP]
    Attention: 0.10  0.15  0.20  0.15  0.25  0.15
                                        â†‘
                        Le token "good" s'auto-observe fortement

**Ã‰tape 3 : PondÃ©ration des valeurs**

La sortie agrÃ¨ge les informations des autres tokens selon ces poids :

.. math::
   
   \text{output}_4 = \sum_j \alpha_{4,j} \cdot value_j

---

Visualisation du Processus
==========================

Voici un diagramme du flux d'attention dans un Transformer :

.. code-block:: text

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      TOKEN INPUT                         â”‚
    â”‚  "The film is good"                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   QUERY Ã— KEY SCORES                     â”‚
    â”‚  [Combien chaque token regarde l'autre]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SOFTMAX NORMALIZATION                  â”‚
    â”‚  [Conversion en probabilitÃ©s]            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ATTENTION WEIGHTS                      â”‚
    â”‚   [Poids finaux: 0.10, 0.15, ...]        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   VALUE WEIGHTING                        â”‚
    â”‚  [AgrÃ©gation pondÃ©rÃ©e des infos]         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   OUTPUT EMBEDDING                       â”‚
    â”‚  [Nouvelle reprÃ©sentation du token]      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

Le PiÃ¨ge de l'InterprÃ©tation NaÃ¯ve
==================================

InterprÃ©tation Courante (INCORRECTE)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Un praticien observe :

.. code-block:: text

    Poids d'attention pour la classe POSITIVE :
    
    "The"     â†’ 0.05  [faible]
    "film"    â†’ 0.10  [faible]
    "is"      â†’ 0.08  [faible]
    "good"    â†’ 0.70  [TRÃˆS Ã‰LEVÃ‰] âœ“
    [SEP]     â†’ 0.07  [faible]

Et conclut naÃ¯vement :

    Â« Le modÃ¨le regarde le mot "good", donc c'est ce mot qui explique la prÃ©diction POSITIVE. Â»

Pourquoi c'est Trompeur
~~~~~~~~~~~~~~~~~~~~~~~~

Cette interprÃ©tation confond **observation** avec **causalitÃ©**.

Les poids d'attention Ã©levÃ©s ne garantissent **pas** que le token influe rÃ©ellement sur la dÃ©cision. 

Les raisons incluent :

1. **Biais syntaxique** ğŸ“
   
   L'attention peut se concentrer sur des tokens importants **syntaxiquement** (verbes, noms) sans lien avec la dÃ©cision.

2. **RÃ´le contextuel** ğŸ”—
   
   Un token peut Ãªtre important pour construire la reprÃ©sentation sans influencer la classification finale.

3. **DÃ©pendance positionnelle** ğŸ“
   
   Les positions du dÃ©but ou fin de phrase reÃ§oivent parfois plus d'attention indÃ©pendamment du contenu.

4. **Bruit d'optimisation** ğŸ²
   
   Pendant l'entraÃ®nement, les poids d'attention peuvent se stabiliser sur des patterns non causaux.

---

Illustration avec un Exemple ProblÃ©matique
===========================================

ConsidÃ©rez deux phrases :

.. code-block:: text

    Phrase A: "This movie is NOT good"
    Phrase B: "This movie is good"

**PrÃ©diction du modÃ¨le** : Les deux donnent NEGATIVE et POSITIVE respectivement âœ“

**Attention observÃ©e** :

.. code-block:: text

    Phrase A:
    "This"  â†’ 0.12
    "movie" â†’ 0.15
    "is"    â†’ 0.10
    "NOT"   â†’ 0.08  â† PROBLÃˆME ! Poids faible
    "good"  â†’ 0.55  â† Attention Ã©levÃ©e pour "good"
    
    Phrase B:
    "This"  â†’ 0.12
    "movie" â†’ 0.15
    "is"    â†’ 0.10
    "good"  â†’ 0.56  â† Poids similaire !

**Conclusion** :

    âš ï¸ Le mot "NOT" devrait Ãªtre CRUCIAL pour inverser le sentiment, 
    mais l'attention ne lui donne pas de poids correspondant !

C'est une **signature d'un dÃ©calage entre attention et causalitÃ©**.

---

Pourquoi l'Attention Peut Ã‰chouer
==================================

Facteurs d'Erreur
~~~~~~~~~~~~~~~~~

.. list-table::
   :header-rows: 1

   * - Facteur
     - MÃ©canisme
     - ConsÃ©quence
   * - **Multi-tÃªtes**
     - DiffÃ©rentes tÃªtes d'attention peuvent capturer des patterns contradictoires
     - AgrÃ©gation arbitraire masque les vÃ©ritables causas
   * - **Biais positionnel**
     - L'attention privilÃ©gie certaines positions (dÃ©but, fin) indÃ©pendamment du contenu
     - Faux positifs pour les tokens positionnÃ©s favorablement
   * - **RÃ´le distributionnel**
     - Un token important pour la syntaxe peut ne pas influencer la classification
     - Confusion entre importance structurelle et prÃ©dictive
   * - **DÃ©couplage**
     - Modifier les poids d'attention ne change pas la prÃ©diction (de maniÃ¨re prÃ©visible)
     - Poids d'attention â‰  rÃ©ellement causal
   * - **Non-spÃ©cificitÃ© de la tÃ¢che**
     - L'attention est globale, pas spÃ©cifiquement orientÃ©e vers la tÃ¢che de classification
     - Bruit non pertinent pour la dÃ©cision
   * - **InstabilitÃ© numÃ©rique**
     - Softmax rend difficile la distinction entre poids importants et moins importants
     - Amplification artificielle des petites diffÃ©rences

---

Comparison : Attention vs Explication RÃ©elle
============================================

Analogie Humaine
~~~~~~~~~~~~~~~~

Imaginez demander Ã  quelqu'un :

    Â« Pourquoi tu crois que ce film est bon ? Â»

**RÃ©ponse par "attention"** (ce qu'il regarde) :

    Â« Je regardais surtout l'action et les effets spÃ©ciaux. Â»
    
    (Mais cela ne dit pas si ces Ã©lÃ©ments ont **rÃ©ellement** influencÃ© son opinion)

**RÃ©ponse par "explication causale"** (ce qui cause vraiment) :

    Â« La raison principale, c'est la qualitÃ© du scÃ©nario, suivi par les acteurs. Â»
    
    (Cela rÃ©vÃ¨le les vÃ©ritables leviers de la dÃ©cision)

Les deux ne sont **pas Ã©quivalentes** !

---

Langage Technique
~~~~~~~~~~~~~~~~~~

+---------------------+------------------------------+-----------------------------+
| Aspect              | ATTENTION                    | EXPLICATION CAUSALE         |
+=====================+==============================+=============================+
| **Nature**          | ProbabilitÃ© de consultation  | Influence rÃ©elle            |
+---------------------+------------------------------+-----------------------------+
| **FiabilitÃ©**       | Incertaine (contexte)        | ValidÃ©e par test            |
+---------------------+------------------------------+-----------------------------+
| **Manipulation**     | Modifiable sans effet        | Affecte la prÃ©diction       |
+---------------------+------------------------------+-----------------------------+
| **IntÃ©rprÃ©tabilitÃ©**| Facile visuellement          | Plus difficile Ã  extraire   |
+---------------------+------------------------------+-----------------------------+
| **Exemple**         | "Le modÃ¨le regarde ce mot"   | "Ce mot change la dÃ©cision" |
+---------------------+------------------------------+-----------------------------+

---

La NÃ©cessitÃ© d'une Validation Empirique
========================================

Face Ã  cette ambiguÃ¯tÃ©, une seule solution : **tester empiriquement** !

Approche
~~~~~~~~

1. **Extraire** les poids d'attention du modÃ¨le
2. **Comparer** avec des mÃ©thodes d'explication Ã©tablies (LIME, SHAP)
3. **Calculer** une corrÃ©lation statistique
4. **Tirer** des conclusions sur la fiabilitÃ© de l'attention

Si :

.. math::
   
   \text{CorrÃ©lation(Attention, LIME)} \approx 1 \quad \Rightarrow \quad \text{Attention est fiable}
   
   \text{CorrÃ©lation(Attention, LIME)} \approx 0 \quad \Rightarrow \quad \text{Attention n'explique rien}

---

Roadmap de l'Ã‰tude
===================

Pour tester ces hypothÃ¨ses :

âœ“ **Section 3** : Formalisation mathÃ©matique  
âœ“ **Section 4** : Code et implÃ©mentation  
âœ“ **Section 5** : ExpÃ©riences et rÃ©sultats  
âœ“ **Section 6** : Analyse critique  

.. button-ref:: 3_formalisation_mathematique
   :color: primary
   :outline:

   Continuer vers les Ã‰quations â†’

---
