.. _getting-started:

===============
D√©marrage Rapide
===============

Bienvenue. Cette page pr√©sente des instructions pour d√©marrer rapidement.

---

Option 1 : Lire la documentation en ligne (recommand√©)
==========================================================

Si vous avez acc√®s √† une version construite de cette documentation, naviguez simplement :

1. Commencez par l'**index** (vous √™tes peut-√™tre d√©j√† ici)
2. Allez √† **Section 1 : Contexte & Motivation**
3. Progressez lin√©airement ou sautez aux sections qui vous int√©ressent

Dur√©e estim√©e : 1-3 heures (selon profondeur).

---

Option 2 : Construire Localement (5 minutes)
=============================================

Si vous disposez des sources (d√©p√¥t clon√©) :

**Pr√©-requis** : Python 3.8+, pip

**√âtapes** :

.. code-block:: bash

    # 1. Naviguer au dossier docs
    cd read-the-doc/docs
    
    # 2. Installer les d√©pendances
    pip install -r requirements.txt
    
    # 3. Construire le HTML
    make html
    
    # 4. Ouvrir dans le navigateur
    # Sur macOS/Linux :
    open build/html/index.html
    
    # Sur Windows :
    start build\html\index.html

**R√©sultat** : Documentation HTML locale accessible hors ligne.

---

Option 3 : Lire les Fichiers .rst Directement
==============================================

Les fichiers sources sont en format reStructuredText (.rst) :

.. code-block:: bash

    # Naviguer au dossier source
    cd read-the-doc/docs/source
    
    # Lire avec n'importe quel √©diteur de texte
    cat 1_contexte_motivation.rst
    cat 2_intuition_methode.rst
    # ... etc

**Inconv√©nient** : Pas de formatage HTML/PDF, juste du texte brut.

---

Option 4 : Ex√©cuter le Notebook Jupyter
========================================

Pour les exp√©riences pratiques :

**Pr√©-requis** : 
- Jupyter (`pip install jupyter`)
- PyTorch, Transformers, LIME, SHAP (voir section Impl√©mentation)

**√âtapes** :

.. code-block:: bash

    # 1. Naviguer au dossier
    cd read-the-doc
    
    # 2. Lancer Jupyter
    jupyter notebook
    
    # 3. Ouvrir Projet7_Attention_Not_Explanation.ipynb
    # 4. Ex√©cuter les cellules s√©quentiellement

**Dur√©e** : ~20-30 minutes pour tout.

---

Parcours Recommand√© par Profil
===============================

Je Suis... √âtudiante en IA
~~~~~~~~~~~~~~~~~~~~~~~~~~

**Temps disponible** : 4 heures  
**Chemin** :

1. Lire Section 1 (Contexte) - 30 min
2. Lire Section 2 (Intuition) - 45 min
3. Lire Section 3 (Maths) - 1h 15 min
4. Parcourir Section 5 (R√©sultats) - 30 min
5. Lire Section 6 (Critique) - 1h
6. **Total** : ~4h

**Ressources** :
- Focus : Comprendre le d√©bat scientifique
- Ignorer : Code d√©taill√© (pour l'instant)
- Consulter : Glossaire au besoin

---

Je Suis... Data Scientist
~~~~~~~~~~~~~~~~~~~~~~~~~~

**Temps disponible** : 3 heures  
**Chemin** :

1. Survol Section 1 - 15 min
2. Sauter Section 2-3 (assum√© connu) - 0 min
3. Lire Section 4 (Code) - 45 min
4. Ex√©cuter le Notebook - 1h 15 min
5. Lire Section 6 (Recommandations) - 30 min
6. **Total** : ~3h

**Ressources** :
- Focus : Code et r√©sultats pratiques
- Important : Savoir quand utiliser attention/LIME/SHAP
- Consulter : FAQ pour questions techniques

---

Je Suis... Chercheur en NLP
~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Temps disponible** : 8 heures  
**Chemin** :

1. Lire tout (sections 1-8) - 5h
2. Relire les articles cl√©s (Jain, Wiegreffe, Serrano) - 2h
3. Ex√©cuter le notebook et exp√©rimenter - 1h
4. **Total** : ~8h

**Ressources** :
- Focus : Rigueur scientifique, √©tats de l'art
- Important : Lire les r√©f√©rences
- Consulter : Glossaire acad√©mique

---

Je Suis... Product Manager / D√©cisionnaire
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Temps disponible** : 1 heure  
**Chemin** :

1. Lire cette page - 10 min
2. Lire Section 1 (Contexte) - 20 min
3. Lire Section 6 (Recommandations) + Section 7 (Conclusion) - 20 min
4. Consulter FAQ si questions - 10 min
5. **Total** : ~1h

**Ressources** :
- Focus : Implications pratiques et recommandations
- Ignorer : Maths d√©taill√©es, code
- Key takeaway : "Utiliser LIME/SHAP pour les d√©cisions critiques"

---

Checklist de D√©marrage
======================

Avant de vous lancer :

.. list-table::
   :header-rows: 1

   * - √âl√©ment
     - √Ä V√©rifier
   * - Python 3.8+
     - ``python --version``
   * - Pip √† jour
     - ``pip --version``
   * - Git (optionnel)
     - ``git --version``
   * - Editeur de texte/IDE
     - VSCode, PyCharm, Jupyter, etc.
   * - Au moins 2 Go RAM
     - Pour ex√©cuter le notebook
   * - Connexion Internet
     - Pour t√©l√©charger les mod√®les

---

Premiers Pas : Ex√©cuter le Code (5 min)
=======================================

Si vous voulez essayer imm√©diatement :

.. code-block:: python

    # 1. Installation
    pip install torch transformers lime shap matplotlib seaborn pandas numpy scipy
    
    # 2. Code minimal (voir notebook pour version compl√®te)
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    
    tokenizer = AutoTokenizer.from_pretrained(
        "distilbert-base-uncased-finetuned-sst-2-english"
    )
    model = AutoModelForSequenceClassification.from_pretrained(
        "distilbert-base-uncased-finetuned-sst-2-english",
        output_attentions=True
    )
    
    text = "This movie is fantastic!"
    inputs = tokenizer(text, return_tensors="pt")
    outputs = model(**inputs)
    
    print("Attention shape:", outputs.attentions[0].shape)
    print("Prediction:", model(**inputs).logits)

**R√©sultat** :

.. code-block:: text

    Attention shape: torch.Size([1, 12, 9, 9])
    Prediction: tensor([[-4.2367, 4.5634]])

Exemple : extraction des poids d'attention affich√©e ci-dessus.

---

Premi√®re Question : Par O√π Commencer ?
======================================

**Si vous souhaitez voir rapidement les r√©sultats**

‚Üí Acc√©dez √† **Section 5 : Exp√©riences & Visualisations**

Vous verrez les r√©sultats maintenant. Revenez ensuite aux sections 1-4 pour le contexte d√©taill√©.

---

**Si vous aimez construire les fondations** üèó

‚Üí Commencez par **Section 1 : Contexte & Motivation**

Progressez lin√©airement. C'est plus logique et plus complet.

---

**Si vous avez des questions sp√©cifiques**

‚Üí Consultez la **FAQ**

La FAQ couvre les questions les plus fr√©quentes.

---

Prochaines √âtapes
=================

Une fois que vous avez parcouru cette page :

1. **Choisissez votre parcours** selon votre profil ci-dessus
2. **Rendez-vous √† l'Index** pour naviguer
3. **Consultez le Glossaire** si vous √™tes bloqu√©e/bloqu√© sur un terme
4. **Ex√©cutez le Notebook** pour exp√©rimenter
5. **Partagez vos questions** via Issues ou Discussions

---

Ressources Rapides
==================

.. list-table::
   :header-rows: 1

   * - Ressource
     - Acc√®s
   * - **Index principal**
     - Lien dans le menu
   * - **Glossaire**
     - Lien dans le menu
   * - **FAQ**
     - Lien dans le menu
   * - **Notebook Jupyter**
     - Fichier `Projet7_Attention_Not_Explanation.ipynb`
   * - **Source .rst**
     - Dossier `docs/source/`

---

Aide et Support
===============

Coinc√©e/Coinc√© ? Besoin d'aide ?

- **Question conceptuelle** ‚Üí FAQ ou Glossaire
- **Bug de code** ‚Üí Notebook `4_implementation_pratique.rst`
- **Question scientifique** ‚Üí Section `6_discussion_critique.rst`
- **Probl√®me technique** ‚Üí README.md ou Issues GitHub

---

D√©marrage
=========

Vous pouvez d√©sormais parcourir la documentation selon votre rythme.

N'h√©sitez pas √† poser des questions via les issues ou discussions du d√©p√¥t.

Bonne lecture.

---

*Derni√®re mise √† jour : D√©cembre 2025*
